{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e54853b6",
   "metadata": {},
   "source": [
    "# Exercise 4: Automatic Speech Recognition (ASR) System"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17dd17c2",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a5e767ab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting vosk\n",
      "  Downloading vosk-0.3.45-py3-none-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (1.8 kB)\n",
      "Requirement already satisfied: soundfile in /opt/conda/lib/python3.7/site-packages (0.12.1)\n",
      "Collecting jiwer\n",
      "  Downloading jiwer-3.0.5-py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting noisereduce\n",
      "  Downloading noisereduce-3.0.3-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.7/site-packages (1.4.1)\n",
      "Collecting webrtcvad\n",
      "  Downloading webrtcvad-2.0.10.tar.gz (66 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.2/66.2 kB\u001b[0m \u001b[31m29.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting tabulate\n",
      "  Downloading tabulate-0.9.0-py3-none-any.whl.metadata (34 kB)\n",
      "Requirement already satisfied: cffi>=1.0 in /opt/conda/lib/python3.7/site-packages (from vosk) (1.14.0)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from vosk) (2.23.0)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.7/site-packages (from vosk) (4.45.0)\n",
      "Collecting srt (from vosk)\n",
      "  Downloading srt-3.5.3.tar.gz (28 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting websockets (from vosk)\n",
      "  Downloading websockets-11.0.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
      "Collecting click<9.0.0,>=8.1.3 (from jiwer)\n",
      "  Downloading click-8.1.8-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting rapidfuzz<4,>=3 (from jiwer)\n",
      "  Downloading rapidfuzz-3.4.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.7/site-packages (from noisereduce) (3.2.1)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from noisereduce) (1.18.4)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.7/site-packages (from noisereduce) (0.14.1)\n",
      "Requirement already satisfied: pycparser in /opt/conda/lib/python3.7/site-packages (from cffi>=1.0->vosk) (2.20)\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from click<9.0.0,>=8.1.3->jiwer) (1.6.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.7/site-packages (from matplotlib->noisereduce) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib->noisereduce) (1.2.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib->noisereduce) (2.4.7)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib->noisereduce) (2.8.1)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests->vosk) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->vosk) (2.9)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->vosk) (1.25.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->vosk) (2020.4.5.1)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from cycler>=0.10->matplotlib->noisereduce) (1.14.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->click<9.0.0,>=8.1.3->jiwer) (3.1.0)\n",
      "Downloading vosk-0.3.45-py3-none-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (7.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m72.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading jiwer-3.0.5-py3-none-any.whl (21 kB)\n",
      "Downloading noisereduce-3.0.3-py3-none-any.whl (22 kB)\n",
      "Downloading tabulate-0.9.0-py3-none-any.whl (35 kB)\n",
      "Downloading click-8.1.8-py3-none-any.whl (98 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.2/98.2 kB\u001b[0m \u001b[31m38.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading rapidfuzz-3.4.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m158.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading websockets-11.0.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (129 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.9/129.9 kB\u001b[0m \u001b[31m59.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: webrtcvad, srt\n",
      "  Building wheel for webrtcvad (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for webrtcvad: filename=webrtcvad-2.0.10-cp37-cp37m-linux_x86_64.whl size=93094 sha256=b8a5ce39d6575e16e8237a7dc2f52b406ee2bc0f5fc6e37dd6d3b4fe06944998\n",
      "  Stored in directory: /home/jovyan/.cache/pip/wheels/11/f9/67/a3158d131f57e1c0a7d8d966a707d4a2fb27567a4fe47723ad\n",
      "  Building wheel for srt (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for srt: filename=srt-3.5.3-py3-none-any.whl size=22426 sha256=b12f6e77141a802d3d171a11897dc53053c20583b30f3f6f446feded23ad56f2\n",
      "  Stored in directory: /home/jovyan/.cache/pip/wheels/08/49/87/bb40987ff98d1b617ac9be9c3b4b5c716888105c971b112871\n",
      "Successfully built webrtcvad srt\n",
      "Installing collected packages: webrtcvad, websockets, tabulate, srt, rapidfuzz, vosk, click, noisereduce, jiwer\n",
      "  Attempting uninstall: click\n",
      "    Found existing installation: click 7.1.2\n",
      "    Uninstalling click-7.1.2:\n",
      "      Successfully uninstalled click-7.1.2\n",
      "Successfully installed click-8.1.8 jiwer-3.0.5 noisereduce-3.0.3 rapidfuzz-3.4.0 srt-3.5.3 tabulate-0.9.0 vosk-0.3.45 webrtcvad-2.0.10 websockets-11.0.3\n"
     ]
    }
   ],
   "source": [
    "!pip install vosk soundfile jiwer noisereduce scipy webrtcvad tabulate\n",
    "\n",
    "import wave\n",
    "import json\n",
    "import numpy as np\n",
    "import unicodedata\n",
    "import string\n",
    "import scipy.signal as sp\n",
    "import librosa as lr\n",
    "import noisereduce as nr\n",
    "from vosk import Model, KaldiRecognizer\n",
    "import soundfile as sf\n",
    "from tabulate import tabulate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98025e05",
   "metadata": {},
   "source": [
    "## Filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3909fff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Noise reduction\n",
    "def dynamic_noise_reduction(audio, sample_rate):\n",
    "    noise_profile = audio[:int(0.5 * sample_rate)]  # Use first 0.5 seconds as noise sample\n",
    "    reduced_audio = nr.reduce_noise(y=audio, sr=sample_rate, y_noise=noise_profile, prop_decrease=0.8)\n",
    "    return reduced_audio\n",
    "\n",
    "# Apply high-pass filter with dynamic cutoff frequency\n",
    "def apply_highpass_filter(audio, sample_rate, lowcut):\n",
    "    sos_high = sp.butter(10, lowcut, btype='high', fs=sample_rate, output='sos')\n",
    "    filtered_audio = sp.sosfilt(sos_high, audio)\n",
    "    return filtered_audio\n",
    "\n",
    "# Normalize and Amplify audio\n",
    "def adaptive_amplify_audio(audio, target_peak=0.9):\n",
    "\n",
    "    max_val = np.max(np.abs(audio))\n",
    "    if max_val > 0:\n",
    "        factor = target_peak / max_val\n",
    "        audio = audio * factor\n",
    "        audio = np.clip(audio, -1.0, 1.0)  # Avoid clipping\n",
    "    return audio\n",
    "\n",
    "# Preprocess audio for a specific lowcut frequency\n",
    "def preprocess_audio(audio_path, target_sample_rate=16000, lowcut=180):\n",
    "    audio, sample_rate = lr.load(audio_path, sr=target_sample_rate, mono=True)\n",
    "    audio_cleaned = dynamic_noise_reduction(audio, sample_rate)\n",
    "    audio_filtered = apply_highpass_filter(audio_cleaned, sample_rate, lowcut)\n",
    "    audio_normalized = adaptive_amplify_audio(audio_filtered, target_peak=0.5)\n",
    "    return audio_normalized, sample_rate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07a22d21",
   "metadata": {},
   "source": [
    "## Post Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8554d21e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize text\n",
    "def normalize_text(text):\n",
    "    text = ''.join(c for c in unicodedata.normalize('NFD', text) if unicodedata.category(c) != 'Mn')\n",
    "    text = text.lower()\n",
    "    contractions = {\n",
    "        \"i've\": \"i have\",\n",
    "        \"where's\": \"where is\",\n",
    "    }\n",
    "    for contraction, expanded in contractions.items():\n",
    "        text = text.replace(contraction, expanded)\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation + '¿¡'))\n",
    "    text = text.replace(\"checkin\", \"check in\")\n",
    "    return text\n",
    "\n",
    "# Calculate WER\n",
    "def calculate_wer(reference, hypothesis):\n",
    "    ref_words = reference.split()\n",
    "    hyp_words = hypothesis.split()\n",
    "    n = len(ref_words)\n",
    "    d = np.zeros((len(ref_words) + 1, len(hyp_words) + 1))\n",
    "    for i in range(len(ref_words) + 1):\n",
    "        d[i, 0] = i\n",
    "    for j in range(len(hyp_words) + 1):\n",
    "        d[0, j] = j\n",
    "    for i in range(1, len(ref_words) + 1):\n",
    "        for j in range(1, len(hyp_words) + 1):\n",
    "            if ref_words[i - 1] == hyp_words[j - 1]:\n",
    "                d[i, j] = d[i - 1, j - 1]\n",
    "            else:\n",
    "                d[i, j] = min(\n",
    "                    d[i - 1, j - 1] + 1,  # Substitution\n",
    "                    d[i, j - 1] + 1,      # Insertion\n",
    "                    d[i - 1, j] + 1       # Deletion\n",
    "                )\n",
    "    return d[-1, -1] / n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dd5535b",
   "metadata": {},
   "source": [
    "## Model Initialization & Transcription"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8fadabf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model\n",
    "def initialize_model(language_model_path):\n",
    "    model = Model(language_model_path)\n",
    "    return model\n",
    "\n",
    "# Transcribe audio\n",
    "def transcribe_audio(model, audio_path, lowcut):\n",
    "    audio, sample_rate = preprocess_audio(audio_path, lowcut=lowcut)\n",
    "    sf.write(f\"filtered_audio_{lowcut}.wav\", audio, sample_rate)\n",
    "    recognizer = KaldiRecognizer(model, sample_rate)\n",
    "    with wave.open(f\"filtered_audio_{lowcut}.wav\", \"rb\") as wf:\n",
    "        results = []\n",
    "        while True:\n",
    "            data = wf.readframes(4000)\n",
    "            if len(data) == 0:\n",
    "                break\n",
    "            if recognizer.AcceptWaveform(data):\n",
    "                result = json.loads(recognizer.Result())\n",
    "                results.append(result[\"text\"])\n",
    "        final_result = json.loads(recognizer.FinalResult())\n",
    "        results.append(final_result[\"text\"])\n",
    "    return \" \".join(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0ecd6e9",
   "metadata": {},
   "source": [
    "## Logic Process "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5107475b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Evaluating EN Audio Files ---\n",
      "+------------+-----------------------------------+-------------+-------------+------------+\n",
      "| Language   | File                              | 180Hz WER   | 250Hz WER   | Best WER   |\n",
      "+============+===================================+=============+=============+============+\n",
      "| EN         | Audio/EN/checkin.wav              | 0.00%       | 0.00%       | 0.00%      |\n",
      "+------------+-----------------------------------+-------------+-------------+------------+\n",
      "| EN         | Audio/EN/checkin_child.wav        | 0.00%       | 0.00%       | 0.00%      |\n",
      "+------------+-----------------------------------+-------------+-------------+------------+\n",
      "| EN         | Audio/EN/parents.wav              | 20.00%      | 60.00%      | 20.00%     |\n",
      "+------------+-----------------------------------+-------------+-------------+------------+\n",
      "| EN         | Audio/EN/parents_child.wav        | 20.00%      | 20.00%      | 20.00%     |\n",
      "+------------+-----------------------------------+-------------+-------------+------------+\n",
      "| EN         | Audio/EN/suitcase.wav             | 0.00%       | 0.00%       | 0.00%      |\n",
      "+------------+-----------------------------------+-------------+-------------+------------+\n",
      "| EN         | Audio/EN/suitcase_child.wav       | 50.00%      | 16.67%      | 16.67%     |\n",
      "+------------+-----------------------------------+-------------+-------------+------------+\n",
      "| EN         | Audio/EN/what_time.wav            | 0.00%       | 40.00%      | 0.00%      |\n",
      "+------------+-----------------------------------+-------------+-------------+------------+\n",
      "| EN         | Audio/EN/what_time_child.wav      | 20.00%      | 20.00%      | 20.00%     |\n",
      "+------------+-----------------------------------+-------------+-------------+------------+\n",
      "| EN         | Audio/EN/where.wav                | 0.00%       | 0.00%       | 0.00%      |\n",
      "+------------+-----------------------------------+-------------+-------------+------------+\n",
      "| EN         | Audio/EN/where_child.wav          | 0.00%       | 0.00%       | 0.00%      |\n",
      "+------------+-----------------------------------+-------------+-------------+------------+\n",
      "| EN         | Audio/i_love_computer_science.wav | 0.00%       | 0.00%       | 0.00%      |\n",
      "+------------+-----------------------------------+-------------+-------------+------------+\n",
      "| EN         | Audio/my_name_is_david.wav        | 0.00%       | 0.00%       | 0.00%      |\n",
      "+------------+-----------------------------------+-------------+-------------+------------+\n",
      "\n",
      "--- Evaluating IT Audio Files ---\n",
      "+------------+---------------------------+-------------+-------------+------------+\n",
      "| Language   | File                      | 180Hz WER   | 250Hz WER   | Best WER   |\n",
      "+============+===========================+=============+=============+============+\n",
      "| IT         | Audio/IT/checkin_it.wav   | 0.00%       | 0.00%       | 0.00%      |\n",
      "+------------+---------------------------+-------------+-------------+------------+\n",
      "| IT         | Audio/IT/parents_it.wav   | 0.00%       | 0.00%       | 0.00%      |\n",
      "+------------+---------------------------+-------------+-------------+------------+\n",
      "| IT         | Audio/IT/suitcase_it.wav  | 0.00%       | 28.57%      | 0.00%      |\n",
      "+------------+---------------------------+-------------+-------------+------------+\n",
      "| IT         | Audio/IT/what_time_it.wav | 14.29%      | 28.57%      | 14.29%     |\n",
      "+------------+---------------------------+-------------+-------------+------------+\n",
      "| IT         | Audio/IT/where_it.wav     | 14.29%      | 14.29%      | 14.29%     |\n",
      "+------------+---------------------------+-------------+-------------+------------+\n",
      "\n",
      "--- Evaluating ES Audio Files ---\n",
      "+------------+---------------------------+-------------+-------------+------------+\n",
      "| Language   | File                      | 180Hz WER   | 250Hz WER   | Best WER   |\n",
      "+============+===========================+=============+=============+============+\n",
      "| ES         | Audio/ES/checkin_es.wav   | 0.00%       | 0.00%       | 0.00%      |\n",
      "+------------+---------------------------+-------------+-------------+------------+\n",
      "| ES         | Audio/ES/parents_es.wav   | 0.00%       | 0.00%       | 0.00%      |\n",
      "+------------+---------------------------+-------------+-------------+------------+\n",
      "| ES         | Audio/ES/suitcase_es.wav  | 0.00%       | 16.67%      | 0.00%      |\n",
      "+------------+---------------------------+-------------+-------------+------------+\n",
      "| ES         | Audio/ES/what_time_es.wav | 33.33%      | 16.67%      | 16.67%     |\n",
      "+------------+---------------------------+-------------+-------------+------------+\n",
      "| ES         | Audio/ES/where_es.wav     | 14.29%      | 14.29%      | 14.29%     |\n",
      "+------------+---------------------------+-------------+-------------+------------+\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    models = {\n",
    "        \"EN\": \"Models/vosk-model-small-en-us-0.15\", \n",
    "        \"IT\": \"Models/vosk-model-small-it-0.22\",\n",
    "        \"ES\": \"Models/vosk-model-small-es-0.42\"\n",
    "    }\n",
    "    language_models = {lang: initialize_model(path) for lang, path in models.items()}\n",
    "    audio_files = {\n",
    "        \"EN\": {\n",
    "            \"Audio/EN/checkin.wav\": \"Where is the check-in desk?\",\n",
    "            \"Audio/EN/checkin_child.wav\": \"Where is the check-in desk?\",\n",
    "            \"Audio/EN/parents.wav\": \"I have lost my parents.\",\n",
    "            \"Audio/EN/parents_child.wav\": \"I have lost my parents.\",\n",
    "            \"Audio/EN/suitcase.wav\": \"Please, I have lost my suitcase.\",\n",
    "            \"Audio/EN/suitcase_child.wav\": \"Please, I have lost my suitcase.\",\n",
    "            \"Audio/EN/what_time.wav\": \"What time is my plane?\",\n",
    "            \"Audio/EN/what_time_child.wav\": \"What time is my plane?\",\n",
    "            \"Audio/EN/where.wav\": \"Where are the restaurants and shops?\",\n",
    "            \"Audio/EN/where_child.wav\": \"Where are the restaurants and shops?\",\n",
    "            \"Audio/i_love_computer_science.wav\": \"I love computer science\",\n",
    "            \"Audio/my_name_is_david.wav\": \"My name is david\"\n",
    "        },\n",
    "        \"IT\": {\n",
    "            \"Audio/IT/checkin_it.wav\": \"Dove e' il bancone?\",\n",
    "            \"Audio/IT/parents_it.wav\": \"Ho perso i miei genitori.\",\n",
    "            \"Audio/IT/suitcase_it.wav\": \"Per favore, ho perso la mia valigia.\",\n",
    "            \"Audio/IT/what_time_it.wav\": \"A che ora e’ il mio aereo?\",\n",
    "            \"Audio/IT/where_it.wav\": \"Dove sono i ristoranti e i negozi?\"\n",
    "        },\n",
    "        \"ES\": {\n",
    "            \"Audio/ES/checkin_es.wav\": \"¿Dónde están los mostradores?\",\n",
    "            \"Audio/ES/parents_es.wav\": \"He perdido a mis padres.\",\n",
    "            \"Audio/ES/suitcase_es.wav\": \"Por favor, he perdido mi maleta.\",\n",
    "            \"Audio/ES/what_time_es.wav\": \"¿A qué hora es mi avión?\",\n",
    "            \"Audio/ES/where_es.wav\": \"¿Dónde están los restaurantes y las tiendas?\"\n",
    "        }\n",
    "    }\n",
    "\n",
    "for language, files in audio_files.items():\n",
    "        print(f\"\\n--- Evaluating {language} Audio Files ---\")\n",
    "        table_data = []\n",
    "        for audio_path, reference in files.items():\n",
    "            # Evaluate for both 180 Hz and 250 Hz\n",
    "            results = {}\n",
    "            for lowcut in [180, 250]:\n",
    "                transcription = transcribe_audio(language_models[language], audio_path, lowcut)\n",
    "                transcription_normalized = normalize_text(transcription)\n",
    "                reference_normalized = normalize_text(reference)\n",
    "                wer = calculate_wer(reference_normalized, transcription_normalized)\n",
    "                results[lowcut] = wer\n",
    "\n",
    "            # Find the best lowcut frequency\n",
    "            best_lowcut = min(results, key=results.get)\n",
    "            best_wer = results[best_lowcut]\n",
    "\n",
    "            # Append row data\n",
    "            table_data.append([\n",
    "                language,\n",
    "                audio_path,\n",
    "                f\"{results[180] * 100:.2f}%\",\n",
    "                f\"{results[250] * 100:.2f}%\",\n",
    "                f\"{best_wer * 100:.2f}%\"\n",
    "            ])\n",
    "\n",
    "        # Print table\n",
    "        print(tabulate(table_data, headers=[\"Language\", \"File\", \"180Hz WER\", \"250Hz WER\", \"Best WER\"], tablefmt=\"grid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5e5312a4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Evaluating EN Audio Files ---\n",
      "\n",
      "Processing file: Audio/EN/checkin.wav\n",
      "Reference: Where is the check-in desk?\n",
      "Transcription at 180 Hz: where is the check in desk\n",
      "Transcription at 250 Hz: where is the check in desk\n",
      "\n",
      "\n",
      "Processing file: Audio/EN/checkin_child.wav\n",
      "Reference: Where is the check-in desk?\n",
      "Transcription at 180 Hz: where's the check in desk \n",
      "Transcription at 250 Hz: where is the check in desk\n",
      "\n",
      "\n",
      "Processing file: Audio/EN/parents.wav\n",
      "Reference: I have lost my parents.\n",
      "Transcription at 180 Hz: i lost my parents\n",
      "Transcription at 250 Hz: i lost my air is\n",
      "\n",
      "\n",
      "Processing file: Audio/EN/parents_child.wav\n",
      "Reference: I have lost my parents.\n",
      "Transcription at 180 Hz: i have lost my area \n",
      "Transcription at 250 Hz: i've lost my area\n",
      "\n",
      "\n",
      "Processing file: Audio/EN/suitcase.wav\n",
      "Reference: Please, I have lost my suitcase.\n",
      "Transcription at 180 Hz: please i've lost my suitcase\n",
      "Transcription at 250 Hz: please i've lost my suitcase\n",
      "\n",
      "\n",
      "Processing file: Audio/EN/suitcase_child.wav\n",
      "Reference: Please, I have lost my suitcase.\n",
      "Transcription at 180 Hz: lemurs i've lost my seeking justice\n",
      "Transcription at 250 Hz: lemurs i've lost my suitcase\n",
      "\n",
      "\n",
      "Processing file: Audio/EN/what_time.wav\n",
      "Reference: What time is my plane?\n",
      "Transcription at 180 Hz: what time is my plane\n",
      "Transcription at 250 Hz: what type is my play\n",
      "\n",
      "\n",
      "Processing file: Audio/EN/what_time_child.wav\n",
      "Reference: What time is my plane?\n",
      "Transcription at 180 Hz: what time is my \n",
      "Transcription at 250 Hz: what time is my \n",
      "\n",
      "\n",
      "Processing file: Audio/EN/where.wav\n",
      "Reference: Where are the restaurants and shops?\n",
      "Transcription at 180 Hz: where are the restaurants and shops\n",
      "Transcription at 250 Hz: where are the restaurants and shops\n",
      "\n",
      "\n",
      "Processing file: Audio/EN/where_child.wav\n",
      "Reference: Where are the restaurants and shops?\n",
      "Transcription at 180 Hz: where are the restaurants and shops\n",
      "Transcription at 250 Hz: where are the restaurants and shops\n",
      "\n",
      "\n",
      "Processing file: Audio/i_love_computer_science.wav\n",
      "Reference: I love computer science\n",
      "Transcription at 180 Hz: i love computer science \n",
      "Transcription at 250 Hz: i love computer science \n",
      "\n",
      "\n",
      "Processing file: Audio/my_name_is_david.wav\n",
      "Reference: My name is david\n",
      "Transcription at 180 Hz: my name is david \n",
      "Transcription at 250 Hz: my name is david \n",
      "\n",
      "\n",
      "--- Evaluating IT Audio Files ---\n",
      "\n",
      "Processing file: Audio/IT/checkin_it.wav\n",
      "Reference: Dove e' il bancone?\n",
      "Transcription at 180 Hz: dove è il bancone\n",
      "Transcription at 250 Hz: dove è il bancone\n",
      "\n",
      "\n",
      "Processing file: Audio/IT/parents_it.wav\n",
      "Reference: Ho perso i miei genitori.\n",
      "Transcription at 180 Hz: ho perso i miei genitori\n",
      "Transcription at 250 Hz: ho perso i miei genitori\n",
      "\n",
      "\n",
      "Processing file: Audio/IT/suitcase_it.wav\n",
      "Reference: Per favore, ho perso la mia valigia.\n",
      "Transcription at 180 Hz: per favore ho perso la mia valigia\n",
      "Transcription at 250 Hz: per favore ho perso una valigia\n",
      "\n",
      "\n",
      "Processing file: Audio/IT/what_time_it.wav\n",
      "Reference: A che ora e’ il mio aereo?\n",
      "Transcription at 180 Hz: a che ora il mio aereo\n",
      "Transcription at 250 Hz: a che ora mio aereo\n",
      "\n",
      "\n",
      "Processing file: Audio/IT/where_it.wav\n",
      "Reference: Dove sono i ristoranti e i negozi?\n",
      "Transcription at 180 Hz: dove sono i ristoranti e negozi\n",
      "Transcription at 250 Hz: dove sono i ristoranti e negozi\n",
      "\n",
      "\n",
      "--- Evaluating ES Audio Files ---\n",
      "\n",
      "Processing file: Audio/ES/checkin_es.wav\n",
      "Reference: ¿Dónde están los mostradores?\n",
      "Transcription at 180 Hz: dónde están los mostradores\n",
      "Transcription at 250 Hz: dónde están los mostradores\n",
      "\n",
      "\n",
      "Processing file: Audio/ES/parents_es.wav\n",
      "Reference: He perdido a mis padres.\n",
      "Transcription at 180 Hz: he perdido a mis padres\n",
      "Transcription at 250 Hz: he perdido a mis padres\n",
      "\n",
      "\n",
      "Processing file: Audio/ES/suitcase_es.wav\n",
      "Reference: Por favor, he perdido mi maleta.\n",
      "Transcription at 180 Hz: por favor he perdido mi maleta\n",
      "Transcription at 250 Hz: por favor perdido mi maleta\n",
      "\n",
      "\n",
      "Processing file: Audio/ES/what_time_es.wav\n",
      "Reference: ¿A qué hora es mi avión?\n",
      "Transcription at 180 Hz: a qué hora es medio\n",
      "Transcription at 250 Hz: a qué hora es mi yo\n",
      "\n",
      "\n",
      "Processing file: Audio/ES/where_es.wav\n",
      "Reference: ¿Dónde están los restaurantes y las tiendas?\n",
      "Transcription at 180 Hz: dónde están los restaurantes las tiendas\n",
      "Transcription at 250 Hz: dónde están los restaurantes las tiendas\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for language, files in audio_files.items():\n",
    "    print(f\"\\n--- Evaluating {language} Audio Files ---\")\n",
    "    for audio_path, reference in files.items():\n",
    "        print(f\"\\nProcessing file: {audio_path}\")\n",
    "\n",
    "        # Dictionary to store transcriptions for both lowcuts\n",
    "        transcriptions = {}\n",
    "\n",
    "        # Evaluate for both 180 Hz and 250 Hz\n",
    "        for lowcut in [180, 250]:\n",
    "            transcription = transcribe_audio(language_models[language], audio_path, lowcut)\n",
    "            transcriptions[lowcut] = transcription\n",
    "\n",
    "        # Print the reference and transcriptions\n",
    "        print(f\"Reference: {reference}\")\n",
    "        print(f\"Transcription at 180 Hz: {transcriptions[180]}\")\n",
    "        print(f\"Transcription at 250 Hz: {transcriptions[250]}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36f1fa6a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
